{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1f3e7a-752d-4d29-aed9-21bf759b976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 15:49:42.310283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748526582.373382    9668 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748526582.394831    9668 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-29 15:49:42.557824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[   INFO   ] MusicExtractorSVM: no classifier models were configured by default\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Model, Input\n",
    "import numpy as np\n",
    "from util import *\n",
    "import os\n",
    "import gc\n",
    "import copy as c\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f440617-15f0-4f48-8656-94ee1792bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "seed = 420\n",
    "batch_size = 256\n",
    "memlen = 100\n",
    "context_radius = 7\n",
    "steps_per_epoch = 200\n",
    "nepochs = 1000\n",
    "nmelbands = 80\n",
    "nchannels = 3\n",
    "npred_steps = 5\n",
    "mem_size = 2500\n",
    "load_checkpoint = False\n",
    "name_from_fp = lambda x: os.path.splitext(os.path.split(x)[1])[0]\n",
    "model_dir = 'trained_models'\n",
    "train_txt_fp = 'json/songs/songs_train.txt'\n",
    "test_txt_fp = 'json/songs/songs_test.txt'\n",
    "feats_dir = 'feats/songs'\n",
    "diff_dict = {\n",
    "    'Beginner': 0,\n",
    "    'Easy': 1,\n",
    "    'Medium': 2,\n",
    "    'Hard': 3,\n",
    "    'Challenge': 4,\n",
    "    'Edit': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21ecf10-35e3-4570-9c74-c780b64d8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_attach(song, song_feats, chart, note_hist, note, next_note, null_frames):\n",
    "    for j in range(null_frames):\n",
    "        for i in range(len(note_hist)-1):\n",
    "            note_hist[i] = note_hist[i+1]\n",
    "        new_time = next_note[2]*((j+1)/(null_frames+1))+note[2]*((null_frames-j)/(null_frames+1))\n",
    "        note_hist[-1] = make_onset_feature_context(song_feats, int(new_time*100), radius = context_radius)\n",
    "        song[0] += [note_hist]\n",
    "        song[2].append([0])\n",
    "        song[1].append([[diff_dict[chart['difficulty_coarse']]] for _ in range(100)])\n",
    "        return song, note_hist\n",
    "    \n",
    "\n",
    "def generatorify_from_fp_list(dataset_fp, \n",
    "                              memlen = 100, \n",
    "                              batch_size = 50, \n",
    "                              mem_size = 10000, \n",
    "                              shuffle = False):\n",
    "    def _gener():\n",
    "        k = 0\n",
    "        hopper = 0\n",
    "        song = None\n",
    "        song_feats = None\n",
    "        with open(dataset_fp, 'r') as f:\n",
    "            json_fps = f.read().splitlines()\n",
    "            json_fps = list(np.unique(json_fps))\n",
    "        np.random.seed(seed)\n",
    "        json_fps = list(np.random.permutation(json_fps))\n",
    "        while True:\n",
    "            while hopper < mem_size:\n",
    "                song = None\n",
    "                hopper = 0\n",
    "                json_fp = json_fps[k]\n",
    "                k = (k + 1) % (len(json_fps) - 1)\n",
    "                with open(json_fp, 'r') as json_f:\n",
    "                    meta = json.loads(json_f.read())\n",
    "                json_name = name_from_fp(json_fp)\n",
    "                song_feats_fp = os.path.join(feats_dir, '{}.pkl'.format(json_name))\n",
    "                with open(song_feats_fp, 'rb') as f:\n",
    "                    song_feats = pickle.load(f)\n",
    "\n",
    "                newsong = [[],[],[]]\n",
    "\n",
    "                for chart in meta['charts']:\n",
    "                    if not chart['type'] or chart['type'] != 'dance-double':\n",
    "                        placed_notes = []\n",
    "                        for note in chart['notes']:\n",
    "                            if note[3] != '0000':\n",
    "                                placed_notes.append(int(round(note[2]*100)))\n",
    "                        for j in range(0,len(song_feats),npred_steps):\n",
    "                            newsong[0]+= [j]\n",
    "                            newsong[1].append([[diff_dict[chart['difficulty_coarse']]] for _ in range(memlen+npred_steps-1)])\n",
    "                            stick_on = []\n",
    "                            for i in range(j,j+5):\n",
    "                                if i in placed_notes:\n",
    "                                    stick_on.append([1])\n",
    "                                else:\n",
    "                                    stick_on.append([0])\n",
    "                            newsong[2].append(stick_on)\n",
    "\n",
    "                if song is None:\n",
    "                    song = newsong\n",
    "                else:\n",
    "                    for j in range(3):\n",
    "                        song[j] = np.append(song[j], newsong[j], axis = 0)\n",
    "                hopper += len(newsong[0])\n",
    "\n",
    "                if shuffle == True:\n",
    "                    for i in range(3):\n",
    "                        np.random.seed(seed)\n",
    "                        song[i] = np.random.permutation(song[i])\n",
    "                gc.collect()\n",
    "            gc.collect()\n",
    "                \n",
    "            assert len(song[0])>5*batch_size\n",
    "\n",
    "            success_take = 0\n",
    "            miss_take = 0\n",
    "            ac = []\n",
    "            sd = []\n",
    "            lb = []\n",
    "            for i in range(0,npred_steps*batch_size,npred_steps):\n",
    "                ac.append(make_onset_feature_context(song_feats, song[0][i], radius = 3+npred_steps, left_radius = memlen+3))\n",
    "                sd.append(song[1][i])\n",
    "                lb.append(song[2][i])\n",
    "                \n",
    "            ac, sd, lb = np.array(ac), np.array(sd), np.squeeze(np.array(lb))\n",
    "            \n",
    "            for j in range(3):\n",
    "                song[j] = song[j][int(npred_steps*batch_size):]\n",
    "            assert(len(song[0])==len(song[1]) and len(song[1])==len(song[2]))\n",
    "            hopper -= npred_steps*batch_size\n",
    "            gc.collect()\n",
    "            yield (ac,sd), lb\n",
    "    return _gener()\n",
    "\n",
    "def get_inputs_and_gens(trn_fp, tst_fp, shuffle = False, batch_size = 1000, memlen = 8, mem_size = 2500):\n",
    "\n",
    "    inp_shape_0 = (None,memlen + 7 + npred_steps ,nmelbands,nchannels)\n",
    "    inp_shape_1 = (None,memlen+npred_steps-1,1)\n",
    "\n",
    "    train_gen = generatorify_from_fp_list(trn_fp, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle = shuffle, \n",
    "                                          mem_size=mem_size,\n",
    "                                          memlen = memlen)\n",
    "    test_gen = generatorify_from_fp_list(tst_fp, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle = shuffle, \n",
    "                                         mem_size=mem_size,\n",
    "                                         memlen = memlen)\n",
    "\n",
    "    audio_ctx_inp = Input(shape = inp_shape_0[1:], batch_size = batch_size)\n",
    "    stream_inp = Input(shape = inp_shape_1[1:], batch_size = batch_size)\n",
    "\n",
    "    return train_gen, test_gen, audio_ctx_inp, stream_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c02b06-9725-425b-bec7-5efbac86221b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">289,600</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,456</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m3\u001b[0m) │         \u001b[38;5;34m12\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m78\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m10\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m26\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m10\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m24\u001b[0m,    │      \u001b[38;5;34m1,820\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m20\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m20\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m160\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m161\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m104\u001b[0m, \u001b[38;5;34m200\u001b[0m)   │    \u001b[38;5;34m289,600\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │    \u001b[38;5;34m320,800\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m51,456\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m32,896\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │        \u001b[38;5;34m645\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">697,869</span> (2.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m697,869\u001b[0m (2.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">697,863</span> (2.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m697,863\u001b[0m (2.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 540ms/step - acc: 0.9548 - auc: 0.0444 - f1: 0.0176 - loss: 0.1662 - val_acc: 0.9562 - val_auc: 0.1755 - val_f1: 0.1999 - val_loss: 0.1350 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - acc: 0.9728 - auc: 0.3953 - f1: 0.2504 - loss: 0.0746 - val_acc: 0.9650 - val_auc: 0.2253 - val_f1: 0.0240 - val_loss: 0.1169 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 529ms/step - acc: 0.9746 - auc: 0.3720 - f1: 0.2001 - loss: 0.0720 - val_acc: 0.9667 - val_auc: 0.4058 - val_f1: 0.4605 - val_loss: 0.0886 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 611ms/step - acc: 0.9788 - auc: 0.5078 - f1: 0.4555 - loss: 0.0617 - val_acc: 0.9703 - val_auc: 0.1459 - val_f1: 0.0994 - val_loss: 0.1206 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 537ms/step - acc: 0.9757 - auc: 0.4500 - f1: 0.3866 - loss: 0.0685 - val_acc: 0.9636 - val_auc: 0.2505 - val_f1: 0.2601 - val_loss: 0.1163 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 585ms/step - acc: 0.9708 - auc: 0.6336 - f1: 0.5821 - loss: 0.0742 - val_acc: 0.9712 - val_auc: 0.2891 - val_f1: 0.1910 - val_loss: 0.1044 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 573ms/step - acc: 0.9757 - auc: 0.5085 - f1: 0.4477 - loss: 0.0692 - val_acc: 0.9761 - val_auc: 0.3402 - val_f1: 0.2350 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 591ms/step - acc: 0.9703 - auc: 0.3384 - f1: 0.2321 - loss: 0.0918 - val_acc: 0.9758 - val_auc: 0.4583 - val_f1: 0.3231 - val_loss: 0.0655 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 551ms/step - acc: 0.9764 - auc: 0.4776 - f1: 0.4063 - loss: 0.0687 - val_acc: 0.9692 - val_auc: 0.3859 - val_f1: 0.1545 - val_loss: 0.0936 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 594ms/step - acc: 0.9751 - auc: 0.5194 - f1: 0.4511 - loss: 0.0700 - val_acc: 0.9624 - val_auc: 0.2915 - val_f1: 0.3601 - val_loss: 0.1028 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 590ms/step - acc: 0.9748 - auc: 0.4734 - f1: 0.4089 - loss: 0.0721 - val_acc: 0.9778 - val_auc: 0.1995 - val_f1: 0.1178 - val_loss: 0.0966 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 599ms/step - acc: 0.9664 - auc: 0.5245 - f1: 0.4616 - loss: 0.0946 - val_acc: 0.9757 - val_auc: 0.3819 - val_f1: 0.4069 - val_loss: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 534ms/step - acc: 0.9780 - auc: 0.4871 - f1: 0.4371 - loss: 0.0633 - val_acc: 0.9614 - val_auc: 0.3854 - val_f1: 0.1554 - val_loss: 0.1159 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 609ms/step - acc: 0.9698 - auc: 0.5034 - f1: 0.3882 - loss: 0.0779 - val_acc: 0.9646 - val_auc: 0.4095 - val_f1: 0.2740 - val_loss: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 595ms/step - acc: 0.9730 - auc: 0.4926 - f1: 0.4027 - loss: 0.0721 - val_acc: 0.9646 - val_auc: 0.2966 - val_f1: 0.1995 - val_loss: 0.1134 - learning_rate: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 576ms/step - acc: 0.9783 - auc: 0.5113 - f1: 0.4668 - loss: 0.0650 - val_acc: 0.9682 - val_auc: 0.3860 - val_f1: 0.2493 - val_loss: 0.0880 - learning_rate: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - acc: 0.9759 - auc: 0.5277 - f1: 0.4359 - loss: 0.0640 - val_acc: 0.9667 - val_auc: 0.3071 - val_f1: 0.1446 - val_loss: 0.0982 - learning_rate: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 598ms/step - acc: 0.9754 - auc: 0.4946 - f1: 0.3578 - loss: 0.0648 - val_acc: 0.9650 - val_auc: 0.2979 - val_f1: 0.2934 - val_loss: 0.1148 - learning_rate: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 546ms/step - acc: 0.9813 - auc: 0.5038 - f1: 0.4313 - loss: 0.0534 - val_acc: 0.9761 - val_auc: 0.5379 - val_f1: 0.5409 - val_loss: 0.0657 - learning_rate: 2.5000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 603ms/step - acc: 0.9769 - auc: 0.4952 - f1: 0.4601 - loss: 0.0619 - val_acc: 0.9705 - val_auc: 0.4723 - val_f1: 0.5110 - val_loss: 0.0825 - learning_rate: 2.5000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 573ms/step - acc: 0.9709 - auc: 0.6404 - f1: 0.5600 - loss: 0.0727 - val_acc: 0.9680 - val_auc: 0.3023 - val_f1: 0.2909 - val_loss: 0.1015 - learning_rate: 2.5000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 621ms/step - acc: 0.9728 - auc: 0.5278 - f1: 0.4653 - loss: 0.0795 - val_acc: 0.9706 - val_auc: 0.3056 - val_f1: 0.2741 - val_loss: 0.0964 - learning_rate: 2.5000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 535ms/step - acc: 0.9710 - auc: 0.3267 - f1: 0.2212 - loss: 0.0879 - val_acc: 0.9780 - val_auc: 0.5026 - val_f1: 0.4268 - val_loss: 0.0622 - learning_rate: 2.5000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 632ms/step - acc: 0.9769 - auc: 0.5210 - f1: 0.4368 - loss: 0.0658 - val_acc: 0.9759 - val_auc: 0.5157 - val_f1: 0.4482 - val_loss: 0.0626 - learning_rate: 2.5000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 548ms/step - acc: 0.9764 - auc: 0.5769 - f1: 0.5206 - loss: 0.0646 - val_acc: 0.9743 - val_auc: 0.5704 - val_f1: 0.4520 - val_loss: 0.0736 - learning_rate: 2.5000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 624ms/step - acc: 0.9786 - auc: 0.4547 - f1: 0.3809 - loss: 0.0628 - val_acc: 0.9742 - val_auc: 0.4810 - val_f1: 0.3529 - val_loss: 0.0724 - learning_rate: 2.5000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 573ms/step - acc: 0.9648 - auc: 0.5910 - f1: 0.4801 - loss: 0.0896 - val_acc: 0.9791 - val_auc: 0.4431 - val_f1: 0.3848 - val_loss: 0.0593 - learning_rate: 2.5000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 667ms/step - acc: 0.9807 - auc: 0.5058 - f1: 0.4615 - loss: 0.0569 - val_acc: 0.9779 - val_auc: 0.4463 - val_f1: 0.3181 - val_loss: 0.0639 - learning_rate: 2.5000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 533ms/step - acc: 0.9662 - auc: 0.5473 - f1: 0.4175 - loss: 0.0855 - val_acc: 0.9608 - val_auc: 0.3573 - val_f1: 0.2798 - val_loss: 0.1194 - learning_rate: 2.5000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 600ms/step - acc: 0.9759 - auc: 0.5342 - f1: 0.4410 - loss: 0.0644 - val_acc: 0.9640 - val_auc: 0.3748 - val_f1: 0.2528 - val_loss: 0.1046 - learning_rate: 2.5000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - acc: 0.9777 - auc: 0.5019 - f1: 0.4283 - loss: 0.0646 - val_acc: 0.9696 - val_auc: 0.5351 - val_f1: 0.4432 - val_loss: 0.0818 - learning_rate: 2.5000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 583ms/step - acc: 0.9747 - auc: 0.4780 - f1: 0.4000 - loss: 0.0681 - val_acc: 0.9704 - val_auc: 0.4927 - val_f1: 0.4091 - val_loss: 0.0845 - learning_rate: 2.5000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 564ms/step - acc: 0.9766 - auc: 0.5877 - f1: 0.4460 - loss: 0.0593 - val_acc: 0.9654 - val_auc: 0.3219 - val_f1: 0.2747 - val_loss: 0.1032 - learning_rate: 1.2500e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 612ms/step - acc: 0.9818 - auc: 0.5365 - f1: 0.4621 - loss: 0.0523 - val_acc: 0.9669 - val_auc: 0.3973 - val_f1: 0.3052 - val_loss: 0.0969 - learning_rate: 1.2500e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 592ms/step - acc: 0.9753 - auc: 0.4578 - f1: 0.3942 - loss: 0.0659 - val_acc: 0.9737 - val_auc: 0.5366 - val_f1: 0.5661 - val_loss: 0.0740 - learning_rate: 1.2500e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 576ms/step - acc: 0.9700 - auc: 0.6161 - f1: 0.5583 - loss: 0.0778 - val_acc: 0.9696 - val_auc: 0.4355 - val_f1: 0.4593 - val_loss: 0.0840 - learning_rate: 1.2500e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 571ms/step - acc: 0.9708 - auc: 0.5316 - f1: 0.4583 - loss: 0.0825 - val_acc: 0.9710 - val_auc: 0.3678 - val_f1: 0.2751 - val_loss: 0.0951 - learning_rate: 1.2500e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 599ms/step - acc: 0.9703 - auc: 0.2571 - f1: 0.1788 - loss: 0.0923 - val_acc: 0.9716 - val_auc: 0.3561 - val_f1: 0.2632 - val_loss: 0.0820 - learning_rate: 6.2500e-05\n",
      "Epoch 39/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 575ms/step - acc: 0.9754 - auc: 0.5462 - f1: 0.4254 - loss: 0.0696 - val_acc: 0.9775 - val_auc: 0.5266 - val_f1: 0.3975 - val_loss: 0.0598 - learning_rate: 6.2500e-05\n",
      "Epoch 40/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 610ms/step - acc: 0.9752 - auc: 0.5584 - f1: 0.4653 - loss: 0.0683 - val_acc: 0.9770 - val_auc: 0.5324 - val_f1: 0.4170 - val_loss: 0.0624 - learning_rate: 6.2500e-05\n",
      "Epoch 41/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 595ms/step - acc: 0.9783 - auc: 0.4569 - f1: 0.4003 - loss: 0.0625 - val_acc: 0.9745 - val_auc: 0.5705 - val_f1: 0.5023 - val_loss: 0.0702 - learning_rate: 6.2500e-05\n",
      "Epoch 42/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 599ms/step - acc: 0.9686 - auc: 0.6140 - f1: 0.5110 - loss: 0.0822 - val_acc: 0.9758 - val_auc: 0.5269 - val_f1: 0.4394 - val_loss: 0.0639 - learning_rate: 6.2500e-05\n",
      "Epoch 43/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 607ms/step - acc: 0.9805 - auc: 0.5085 - f1: 0.4703 - loss: 0.0553 - val_acc: 0.9791 - val_auc: 0.4410 - val_f1: 0.3698 - val_loss: 0.0576 - learning_rate: 3.1250e-05\n",
      "Epoch 44/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 616ms/step - acc: 0.9658 - auc: 0.5324 - f1: 0.3899 - loss: 0.0859 - val_acc: 0.9772 - val_auc: 0.4753 - val_f1: 0.3427 - val_loss: 0.0625 - learning_rate: 3.1250e-05\n",
      "Epoch 45/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 559ms/step - acc: 0.9766 - auc: 0.5685 - f1: 0.4561 - loss: 0.0621 - val_acc: 0.9621 - val_auc: 0.4491 - val_f1: 0.2445 - val_loss: 0.1003 - learning_rate: 3.1250e-05\n",
      "Epoch 46/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 605ms/step - acc: 0.9786 - auc: 0.5136 - f1: 0.4446 - loss: 0.0619 - val_acc: 0.9654 - val_auc: 0.4547 - val_f1: 0.3296 - val_loss: 0.0926 - learning_rate: 3.1250e-05\n",
      "Epoch 47/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 561ms/step - acc: 0.9751 - auc: 0.4781 - f1: 0.3808 - loss: 0.0660 - val_acc: 0.9716 - val_auc: 0.5571 - val_f1: 0.4607 - val_loss: 0.0819 - learning_rate: 3.1250e-05\n",
      "Epoch 48/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 620ms/step - acc: 0.9795 - auc: 0.6051 - f1: 0.5415 - loss: 0.0536 - val_acc: 0.9702 - val_auc: 0.4419 - val_f1: 0.3748 - val_loss: 0.0871 - learning_rate: 3.1250e-05\n",
      "Epoch 49/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 583ms/step - acc: 0.9824 - auc: 0.6189 - f1: 0.5192 - loss: 0.0494 - val_acc: 0.9676 - val_auc: 0.3558 - val_f1: 0.2457 - val_loss: 0.0952 - learning_rate: 1.5625e-05\n",
      "Epoch 50/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 598ms/step - acc: 0.9739 - auc: 0.4980 - f1: 0.4028 - loss: 0.0665 - val_acc: 0.9664 - val_auc: 0.4446 - val_f1: 0.4160 - val_loss: 0.0942 - learning_rate: 1.5625e-05\n",
      "Epoch 51/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 571ms/step - acc: 0.9696 - auc: 0.5869 - f1: 0.5121 - loss: 0.0794 - val_acc: 0.9755 - val_auc: 0.4811 - val_f1: 0.4861 - val_loss: 0.0696 - learning_rate: 1.5625e-05\n",
      "Epoch 52/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 601ms/step - acc: 0.9682 - auc: 0.5003 - f1: 0.3890 - loss: 0.0851 - val_acc: 0.9740 - val_auc: 0.4609 - val_f1: 0.3779 - val_loss: 0.0765 - learning_rate: 1.5625e-05\n",
      "Epoch 53/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 567ms/step - acc: 0.9732 - auc: 0.3681 - f1: 0.2811 - loss: 0.0781 - val_acc: 0.9694 - val_auc: 0.3441 - val_f1: 0.2286 - val_loss: 0.0906 - learning_rate: 1.5625e-05\n",
      "Epoch 54/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 608ms/step - acc: 0.9748 - auc: 0.5780 - f1: 0.4134 - loss: 0.0679 - val_acc: 0.9725 - val_auc: 0.3775 - val_f1: 0.2834 - val_loss: 0.0806 - learning_rate: 7.8125e-06\n",
      "Epoch 55/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 559ms/step - acc: 0.9719 - auc: 0.5424 - f1: 0.3898 - loss: 0.0743 - val_acc: 0.9777 - val_auc: 0.5494 - val_f1: 0.3800 - val_loss: 0.0588 - learning_rate: 7.8125e-06\n",
      "Epoch 56/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 624ms/step - acc: 0.9772 - auc: 0.4727 - f1: 0.3794 - loss: 0.0651 - val_acc: 0.9768 - val_auc: 0.5561 - val_f1: 0.4199 - val_loss: 0.0616 - learning_rate: 7.8125e-06\n",
      "Epoch 57/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 555ms/step - acc: 0.9726 - auc: 0.6085 - f1: 0.4902 - loss: 0.0775 - val_acc: 0.9741 - val_auc: 0.5874 - val_f1: 0.5019 - val_loss: 0.0690 - learning_rate: 7.8125e-06\n",
      "Epoch 58/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 632ms/step - acc: 0.9795 - auc: 0.4918 - f1: 0.4686 - loss: 0.0581 - val_acc: 0.9770 - val_auc: 0.5403 - val_f1: 0.4547 - val_loss: 0.0620 - learning_rate: 7.8125e-06\n",
      "Epoch 59/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 584ms/step - acc: 0.9674 - auc: 0.5125 - f1: 0.3700 - loss: 0.0827 - val_acc: 0.9790 - val_auc: 0.4391 - val_f1: 0.3685 - val_loss: 0.0589 - learning_rate: 3.9063e-06\n",
      "Epoch 60/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 606ms/step - acc: 0.9769 - auc: 0.5765 - f1: 0.4865 - loss: 0.0620 - val_acc: 0.9768 - val_auc: 0.4898 - val_f1: 0.3585 - val_loss: 0.0652 - learning_rate: 3.9063e-06\n",
      "Epoch 61/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 567ms/step - acc: 0.9801 - auc: 0.5592 - f1: 0.4954 - loss: 0.0554 - val_acc: 0.9625 - val_auc: 0.4498 - val_f1: 0.2784 - val_loss: 0.1000 - learning_rate: 3.9063e-06\n",
      "Epoch 62/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 617ms/step - acc: 0.9770 - auc: 0.4449 - f1: 0.3686 - loss: 0.0604 - val_acc: 0.9660 - val_auc: 0.4290 - val_f1: 0.3407 - val_loss: 0.0931 - learning_rate: 3.9063e-06\n",
      "Epoch 63/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 577ms/step - acc: 0.9786 - auc: 0.5795 - f1: 0.4906 - loss: 0.0562 - val_acc: 0.9694 - val_auc: 0.5072 - val_f1: 0.4015 - val_loss: 0.0851 - learning_rate: 3.9063e-06\n",
      "Epoch 64/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 577ms/step - acc: 0.9814 - auc: 0.5936 - f1: 0.5089 - loss: 0.0512 - val_acc: 0.9696 - val_auc: 0.4564 - val_f1: 0.3282 - val_loss: 0.0839 - learning_rate: 1.9531e-06\n",
      "Epoch 65/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 592ms/step - acc: 0.9716 - auc: 0.5410 - f1: 0.4391 - loss: 0.0698 - val_acc: 0.9671 - val_auc: 0.3816 - val_f1: 0.3152 - val_loss: 0.0907 - learning_rate: 1.9531e-06\n",
      "Epoch 66/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 620ms/step - acc: 0.9722 - auc: 0.5769 - f1: 0.4896 - loss: 0.0730 - val_acc: 0.9691 - val_auc: 0.4687 - val_f1: 0.4264 - val_loss: 0.0885 - learning_rate: 1.9531e-06\n",
      "Epoch 67/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 527ms/step - acc: 0.9695 - auc: 0.4845 - f1: 0.3806 - loss: 0.0826 - val_acc: 0.9770 - val_auc: 0.5334 - val_f1: 0.4974 - val_loss: 0.0655 - learning_rate: 1.9531e-06\n",
      "Epoch 68/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 629ms/step - acc: 0.9736 - auc: 0.4355 - f1: 0.3783 - loss: 0.0731 - val_acc: 0.9745 - val_auc: 0.4493 - val_f1: 0.4210 - val_loss: 0.0778 - learning_rate: 1.9531e-06\n",
      "Epoch 69/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 543ms/step - acc: 0.9756 - auc: 0.5942 - f1: 0.4693 - loss: 0.0659 - val_acc: 0.9695 - val_auc: 0.3466 - val_f1: 0.2958 - val_loss: 0.0914 - learning_rate: 1.0000e-06\n",
      "Epoch 70/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 615ms/step - acc: 0.9716 - auc: 0.5416 - f1: 0.4204 - loss: 0.0736 - val_acc: 0.9728 - val_auc: 0.3992 - val_f1: 0.2851 - val_loss: 0.0791 - learning_rate: 1.0000e-06\n",
      "Epoch 71/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 617ms/step - acc: 0.9747 - auc: 0.4554 - f1: 0.3719 - loss: 0.0719 - val_acc: 0.9777 - val_auc: 0.5301 - val_f1: 0.3983 - val_loss: 0.0593 - learning_rate: 1.0000e-06\n",
      "Epoch 72/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 585ms/step - acc: 0.9702 - auc: 0.6376 - f1: 0.4647 - loss: 0.0767 - val_acc: 0.9774 - val_auc: 0.5798 - val_f1: 0.4547 - val_loss: 0.0610 - learning_rate: 1.0000e-06\n",
      "Epoch 73/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 589ms/step - acc: 0.9775 - auc: 0.4351 - f1: 0.4250 - loss: 0.0643 - val_acc: 0.9742 - val_auc: 0.6145 - val_f1: 0.4927 - val_loss: 0.0665 - learning_rate: 1.0000e-06\n",
      "Epoch 74/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 594ms/step - acc: 0.9696 - auc: 0.4822 - f1: 0.3533 - loss: 0.0782 - val_acc: 0.9777 - val_auc: 0.5511 - val_f1: 0.4414 - val_loss: 0.0587 - learning_rate: 1.0000e-06\n",
      "Epoch 75/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 585ms/step - acc: 0.9757 - auc: 0.5807 - f1: 0.4770 - loss: 0.0623 - val_acc: 0.9802 - val_auc: 0.4980 - val_f1: 0.4206 - val_loss: 0.0568 - learning_rate: 1.0000e-06\n",
      "Epoch 76/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 605ms/step - acc: 0.9814 - auc: 0.5820 - f1: 0.5177 - loss: 0.0516 - val_acc: 0.9739 - val_auc: 0.4519 - val_f1: 0.3666 - val_loss: 0.0698 - learning_rate: 1.0000e-06\n",
      "Epoch 77/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 564ms/step - acc: 0.9741 - auc: 0.5437 - f1: 0.3941 - loss: 0.0647 - val_acc: 0.9615 - val_auc: 0.4208 - val_f1: 0.2709 - val_loss: 0.1032 - learning_rate: 1.0000e-06\n",
      "Epoch 78/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 597ms/step - acc: 0.9781 - auc: 0.5827 - f1: 0.4965 - loss: 0.0602 - val_acc: 0.9652 - val_auc: 0.4392 - val_f1: 0.3388 - val_loss: 0.0943 - learning_rate: 1.0000e-06\n",
      "Epoch 79/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 587ms/step - acc: 0.9807 - auc: 0.5553 - f1: 0.4711 - loss: 0.0534 - val_acc: 0.9709 - val_auc: 0.5458 - val_f1: 0.4114 - val_loss: 0.0810 - learning_rate: 1.0000e-06\n",
      "Epoch 80/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 603ms/step - acc: 0.9666 - auc: 0.4940 - f1: 0.3759 - loss: 0.0822 - val_acc: 0.9703 - val_auc: 0.4681 - val_f1: 0.3603 - val_loss: 0.0838 - learning_rate: 1.0000e-06\n",
      "Epoch 81/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 579ms/step - acc: 0.9737 - auc: 0.5593 - f1: 0.4807 - loss: 0.0713 - val_acc: 0.9668 - val_auc: 0.3975 - val_f1: 0.3509 - val_loss: 0.0924 - learning_rate: 1.0000e-06\n",
      "Epoch 82/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 596ms/step - acc: 0.9715 - auc: 0.4649 - f1: 0.3773 - loss: 0.0783 - val_acc: 0.9695 - val_auc: 0.4791 - val_f1: 0.3944 - val_loss: 0.0869 - learning_rate: 1.0000e-06\n",
      "Epoch 83/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 560ms/step - acc: 0.9742 - auc: 0.4750 - f1: 0.4109 - loss: 0.0721 - val_acc: 0.9776 - val_auc: 0.5343 - val_f1: 0.5026 - val_loss: 0.0642 - learning_rate: 1.0000e-06\n",
      "Epoch 84/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 607ms/step - acc: 0.9762 - auc: 0.5694 - f1: 0.4622 - loss: 0.0659 - val_acc: 0.9733 - val_auc: 0.4540 - val_f1: 0.4487 - val_loss: 0.0786 - learning_rate: 1.0000e-06\n",
      "Epoch 85/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 581ms/step - acc: 0.9743 - auc: 0.5782 - f1: 0.4857 - loss: 0.0669 - val_acc: 0.9696 - val_auc: 0.3461 - val_f1: 0.2605 - val_loss: 0.0915 - learning_rate: 1.0000e-06\n",
      "Epoch 86/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 614ms/step - acc: 0.9751 - auc: 0.4863 - f1: 0.4038 - loss: 0.0703 - val_acc: 0.9730 - val_auc: 0.3890 - val_f1: 0.3121 - val_loss: 0.0775 - learning_rate: 1.0000e-06\n",
      "Epoch 87/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 556ms/step - acc: 0.9682 - auc: 0.6322 - f1: 0.4329 - loss: 0.0787 - val_acc: 0.9780 - val_auc: 0.5339 - val_f1: 0.4129 - val_loss: 0.0596 - learning_rate: 1.0000e-06\n",
      "Epoch 88/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 622ms/step - acc: 0.9765 - auc: 0.4557 - f1: 0.4220 - loss: 0.0656 - val_acc: 0.9768 - val_auc: 0.5672 - val_f1: 0.4172 - val_loss: 0.0615 - learning_rate: 1.0000e-06\n",
      "Epoch 89/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 549ms/step - acc: 0.9735 - auc: 0.4752 - f1: 0.3694 - loss: 0.0706 - val_acc: 0.9737 - val_auc: 0.6029 - val_f1: 0.4726 - val_loss: 0.0680 - learning_rate: 1.0000e-06\n",
      "Epoch 90/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 613ms/step - acc: 0.9760 - auc: 0.5892 - f1: 0.4873 - loss: 0.0608 - val_acc: 0.9784 - val_auc: 0.5423 - val_f1: 0.4547 - val_loss: 0.0577 - learning_rate: 1.0000e-06\n",
      "Epoch 91/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 596ms/step - acc: 0.9809 - auc: 0.5936 - f1: 0.5237 - loss: 0.0522 - val_acc: 0.9797 - val_auc: 0.4829 - val_f1: 0.4323 - val_loss: 0.0567 - learning_rate: 1.0000e-06\n",
      "Epoch 92/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 621ms/step - acc: 0.9748 - auc: 0.5284 - f1: 0.4050 - loss: 0.0657 - val_acc: 0.9733 - val_auc: 0.4478 - val_f1: 0.3401 - val_loss: 0.0733 - learning_rate: 1.0000e-06\n",
      "Epoch 93/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 569ms/step - acc: 0.9753 - auc: 0.5822 - f1: 0.4871 - loss: 0.0696 - val_acc: 0.9622 - val_auc: 0.4198 - val_f1: 0.2842 - val_loss: 0.1025 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "train_gen, test_gen, audio_ctx_inp, stream_inp= get_inputs_and_gens(train_txt_fp, \n",
    "                                                                  test_txt_fp,\n",
    "                                                                  shuffle, \n",
    "                                                                  batch_size=batch_size, \n",
    "                                                                  memlen = memlen,\n",
    "                                                                   mem_size = mem_size)\n",
    "\n",
    "audio_proc = layers.BatchNormalization()(audio_ctx_inp)\n",
    "audio_proc = layers.Conv2D(10, (7,3))(audio_proc)\n",
    "audio_proc = layers.MaxPooling2D((1,3), strides = (1,3))(audio_proc)\n",
    "audio_proc = layers.Conv2D(20, (3,3))(audio_proc)\n",
    "audio_proc = layers.MaxPooling2D((1,3), strides = (1,3))(audio_proc)\n",
    "\n",
    "audio_out = layers.Reshape((memlen+npred_steps-1,-1))(audio_proc)\n",
    "\n",
    "stream_merge = layers.Concatenate(axis = -1)([audio_out, stream_inp])\n",
    "\n",
    "note_comp = layers.LSTM(200, return_sequences = True, dropout = .5)(stream_merge)\n",
    "note_comp = layers.LSTM(200, dropout = .5)(note_comp)\n",
    "\n",
    "note_comp = layers.Dense(256, activation = 'relu')(note_comp)\n",
    "note_comp = layers.Dense(128, activation = 'relu')(note_comp)\n",
    "\n",
    "output = layers.Dense(npred_steps, activation = 'sigmoid')(note_comp)\n",
    "\n",
    "model = Model([audio_ctx_inp, stream_inp], output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    #optimizer = tf.keras.optimizers.SGD(learning_rate = 1e-2, clipvalue = 5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    metrics=[\n",
    "    tf.keras.metrics.AUC(from_logits = False, curve = 'PR', name = 'auc'),\n",
    "    tf.keras.metrics.F1Score(average = 'micro', threshold = .5, name = 'f1'),\n",
    "    tf.keras.metrics.BinaryAccuracy(name = 'acc'),\n",
    "],\n",
    ")\n",
    "print(model.summary())\n",
    "checkpoint_filepath = os.path.join(model_dir, 'onset_ddc_checkpoint.keras')\n",
    "if load_checkpoint:\n",
    "    if os.path.isfile(checkpoint_filepath):\n",
    "        print(True)\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose = 0,\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_auc',\n",
    "    mode = 'max')\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    mode = 'max'\n",
    ")\n",
    "\n",
    "model.fit(train_gen, \n",
    "          batch_size = batch_size, \n",
    "          epochs = nepochs, \n",
    "          steps_per_epoch = steps_per_epoch, \n",
    "          validation_steps = 20, \n",
    "          validation_data = test_gen, \n",
    "          callbacks = [model_checkpoint_callback, lr_scheduler, early_stopping])\n",
    "\n",
    "model.save(model_dir + '/onset_ddc_model.keras')\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec57f55-abe0-42e0-87d6-e6a4d50e38c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
